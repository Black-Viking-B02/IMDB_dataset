{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "IMDB dataset.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOzQvtnSRFmjQgSZIUaGite",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Black-Viking-B02/IMDB_dataset/blob/main/IMDB_dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "swPDgweRQyhY",
        "outputId": "21e8e11a-9b43-4755-b648-eda11b4dec0a"
      },
      "source": [
        "from keras.datasets import imdb\r\n",
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "\r\n",
        "(train_data, train_labels) , (test_data , test_labels) = imdb.load_data(num_words=10000)\r\n"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/datasets/imdb.py:159: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/datasets/imdb.py:160: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RrLn5jUlVr5d"
      },
      "source": [
        "word_index = imdb.get_word_index()"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gFqNj3JcWf0g"
      },
      "source": [
        "word_index = imdb.get_word_index()\r\n",
        "reverse_word_index = dict(\r\n",
        "[(value, key) for (key, value) in word_index.items()])\r\n",
        "decoded_review = ' '.join(\r\n",
        "[reverse_word_index.get(i - 3, '?') for i in train_data[0]])\r\n"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xbgakYayaNJe"
      },
      "source": [
        "We have to turn lists into tensors. There are two ways to do that:\r\n",
        "\r\n",
        "\r\n",
        "1.   Pad your lists so that all have the same length, turn them into an integer\r\n",
        "tensor of shape (samples , word_indices), and then use the first layer in your network a layer capable of handling such integer tensors. (Embedding layer)\r\n",
        "2.   One-hot encode your lists to turn them into vectors of 0s and 1s, which \r\n",
        "we're going to do here.\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ZM6sodZbodW"
      },
      "source": [
        "def vectorize_sequences(sequences , dimension = 10000):\r\n",
        "  results = np.zeros(len(sequences) , dimension)\r\n",
        "  for i, sequence in enumerate(sequences):\r\n",
        "    results[i,sequence] = 1\r\n",
        "  return results\r\n",
        "  x_train = vectorize_sequences(train_data)\r\n",
        "  x_test= vectorize_sequences(test_data)\r\n",
        "  x_train"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "opowzn73i31Q"
      },
      "source": [
        "We should also vectorize the labels, which is straightforward."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JAd-7DryjBAP"
      },
      "source": [
        "y_train = np.asarray(train_labels).astype('float32')\r\n",
        "y_test= np.asarray(test_labels).astype('float32')"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IQ2UomtQlLYY"
      },
      "source": [
        "##Model Implementation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FEdIeJaxlOsn"
      },
      "source": [
        "from keras import models\r\n",
        "from keras import layers\r\n",
        "model= models.Sequential()\r\n",
        "model.add(layers.Dense(16, activation='relu', input_shape=(10000,)))\r\n",
        "model.add(layers.Dense(19, activation ='relu'))\r\n",
        "model.add(layers.Dense(1, activation='sigmoid'))"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DMSeX9wTmElE"
      },
      "source": [
        "##Choosing a Loss Function and an Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QWX6HGXomJ4x"
      },
      "source": [
        "model.compile (optimizer='rmsprop',\r\n",
        "               loss='binary_crossentropy',\r\n",
        "               metrics=['accuracy'])"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1PIp6MqQpb1w"
      },
      "source": [
        "##Validating Our Approach"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 214
        },
        "id": "7pai5MAxpf3l",
        "outputId": "ed398e3b-275a-4949-c422-dc8eebf2ef03"
      },
      "source": [
        "x_val = x_train[:10000]\r\n",
        "partial_x_train=x_train[10000:]\r\n",
        "y_val=y_train[:10000]\r\n",
        "partial_y_train= y_train[10000:]"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-a328206ab292>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mpartial_x_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mpartial_y_train\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'x_train' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PTesvamtqESG"
      },
      "source": [
        "##Training th Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "id": "c9cecCEaqINV",
        "outputId": "e87c5a69-1884-463d-caa8-5a78ca56da24"
      },
      "source": [
        "model.compile(optimizer='rmsprop',loss='binary_crossentropy',metrics=['acc'])\r\n",
        "history = model.fit(partial_x_train, partial_y_train, epochs=20,\r\n",
        "                    batch_size=512, validation_data=(x_val, y_val))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-d7f2535ecccf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'rmsprop'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'binary_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m history = model.fit(partial_x_train, partial_y_train, epochs=20,\n\u001b[0m\u001b[1;32m      3\u001b[0m                     batch_size=512, validation_data=(x_val, y_val))\n",
            "\u001b[0;31mNameError\u001b[0m: name 'partial_x_train' is not defined"
          ]
        }
      ]
    }
  ]
}